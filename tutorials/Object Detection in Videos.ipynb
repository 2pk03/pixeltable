{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e380aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, glob, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "import json\n",
    "import urllib.request\n",
    "import tempfile\n",
    "import tqdm\n",
    "\n",
    "import torch, torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d93d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixeltable as pt\n",
    "import pixeltable.functions\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29054d06",
   "metadata": {},
   "source": [
    "# Creating a tutorial database and table\n",
    "\n",
    "In Pixeltable, all data resides in tables, which in turn are assigned to databases.\n",
    "\n",
    "Let's start by creating a client and a `tutorial` database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da120aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = pt.Client()\n",
    "cl.drop_db('tutorial', ignore_errors=True, force=True)\n",
    "db = cl.create_db('tutorial')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9347725",
   "metadata": {},
   "source": [
    "In this tutorial we're going to be a working with a single video file (from Pixeltable's test data directory). Let's download that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef89496",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url = 'https://gitlab.com/pixeltable/python-sdk/-/raw/master/pixeltable/tests/data/videos/bangkok.mp4'\n",
    "filename, _ = urllib.request.urlretrieve(download_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b213cee6",
   "metadata": {},
   "source": [
    "To begin with, the table contains three columns: the original video, the frame and a frame index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38afd8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    pt.Column('video', pt.VideoType(), nullable=False),\n",
    "    pt.Column('frame', pt.ImageType(), nullable=False),\n",
    "    pt.Column('frame_idx', pt.IntType(), nullable=False),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145c4fca",
   "metadata": {},
   "source": [
    "When creating the table, we supply parameters needed for automatic frame extraction during `insert_rows()`/`insert_pandas()` calls:\n",
    "- The `extract_frames_from` argument is the name of the column of type `video` from which to extract frames.\n",
    "- During an `insert_rows()` call, each input row, corresponding to one video, is expanded into one row per frame (subject to the frame rate requested in the `extracted_fps` keyword argument; `0` indicates the full frame rate).\n",
    "- Each frame is extract to a JPEG file that is stored in a location under the Pixeltable home directory.\n",
    "- The columns `frame` and `frame_idx` receive the frame file path and frame sequence number, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd875c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = db.create_table(\n",
    "    'video_data', cols,\n",
    "    extract_frames_from='video', extracted_frame_col='frame', extracted_frame_idx_col='frame_idx',\n",
    "    extracted_fps=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c5d16",
   "metadata": {},
   "source": [
    "We now insert a single row containing the name of the video file we just downloaded, which is expanded into 462 frames/rows in the `video_data` table.\n",
    "\n",
    "In general, `insert_rows()` takes as its first argument a list of rows, each of which is a list of column values (and in this case, we only need to supply data for the `video` column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a12da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.insert_rows([[filename]], columns=['video'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae0de07",
   "metadata": {},
   "source": [
    "We loaded a video that shows a busy intersection in Bangkok. Let's look at the first frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448c3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[t.frame_idx == 0][t.frame, t.frame.width, t.frame.height].show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadd9f26",
   "metadata": {},
   "source": [
    "Running this command takes a bit of time, and the reason is that Pixeltable re-extracts the frames during a query. The default behavior for computed columns of type `image` is not to store the images directly (this can quickly lead to an explosion of required storage when dealing with video data), but to cache them instead, so that repeated accesses to the same column values are fast.\n",
    "\n",
    "Let's try this again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[t.frame_idx == 1][t.frame, t.frame.width, t.frame.height].show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec943e16",
   "metadata": {},
   "source": [
    "Whether a computed image column is stored or cached is controlled by the `stored` keyword argument of the `Column` constructor:\n",
    "- the default is `None` which means that the value is not stored explicitly, but it is cached\n",
    "- when set to `True`, the value is stored explicitly\n",
    "- when set to `False`, the value is always recomputed during a query (and never stored or cached)\n",
    "\n",
    "Let's take another look at the definition of the `frame` column:\n",
    "```python\n",
    "pt.Column('frame', pt.ImageType(), nullable=False)\n",
    "```\n",
    "In this case, we didn't specify `stored`, and so the default applies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755edf69",
   "metadata": {},
   "source": [
    "# Object Detection as a User-Defined Function\n",
    "\n",
    "User-defined functions let you customize Pixeltable's functionality for your own data.\n",
    "\n",
    "In this example, we're going use a `torchvision` object detection model (Faster R-CNN):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(weights=\"DEFAULT\")\n",
    "model.eval()  # switch to inference mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b484dcda",
   "metadata": {},
   "source": [
    "Our function converts the image to PyTorch format and obtains a prediction from the model, which is a list of dictionaries with fields `boxes`, `labels`, and `scores` (one per input image). The fields themselves are PyTorch tensors, and we convert them to standard Python lists (so they become JSON-serializable data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1139a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pt.function(return_type=pt.JsonType(), param_types=[pt.ImageType()])\n",
    "def detect(img):\n",
    "    t = transforms.ToTensor()(img)\n",
    "    t = transforms.ConvertImageDtype(torch.float)(t)\n",
    "    result = model([t])[0]\n",
    "    return {\n",
    "        'boxes': result['boxes'].tolist(), 'labels': result['labels'].tolist(), 'scores': result['scores'].tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0157b86",
   "metadata": {},
   "source": [
    "We can then use `detect()` in the Pixeltable index operator using standard Python function call syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ab9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[t.frame_idx == 0][t.frame, detect(t.frame)].show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f07d2e",
   "metadata": {},
   "source": [
    "This works as expected, and we now add the detections as a computed column `detections` to the table.\n",
    "\n",
    "Running model inference is generally an expensive operation; adding it as a computed column makes sure it only runs once, at the time the row is inserted. After that, the result is available as part of the stored table data.\n",
    "\n",
    "Note that for computed columns of any type other than `image`, the computed values are **always** stored (ie, `stored=True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dab11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.add_column(pt.Column('detections', computed_with=detect(t.frame)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3555b0e8",
   "metadata": {},
   "source": [
    "We can create a simple function `draw_boxes()` to visualize detections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db8593",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pt.function(return_type=pt.ImageType(), param_types=[pt.ImageType(), pt.JsonType()])\n",
    "def draw_boxes(img, boxes):\n",
    "    result = img.copy()\n",
    "    d = PIL.ImageDraw.Draw(result)\n",
    "    for box in boxes:\n",
    "        d.rectangle(box, width=3)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2a429c",
   "metadata": {},
   "source": [
    "This function takes two arguments:\n",
    "- `img` has type `image` and receives an instance of `PIL.Image.Image`\n",
    "- `boxes` has type `json` and receives a JSON-serializable structure, in this case a list of 4-element lists of floats\n",
    "\n",
    "When we \"call\" this function, we need to pass in the frame and the bounding boxes identified in that frame. The latter can be selected with the JSON path expression `t.detections.boxes`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bbd1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[t.frame_idx == 0][t.frame, draw_boxes(t.frame, t.detections.boxes)].show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6943594",
   "metadata": {},
   "source": [
    "Looking at individual frames gives us some idea of how well our detection algorithm works, but it would be more instructive to turn the visualization output back into a video.\n",
    "\n",
    "We can accomplish that with the built-in function `make_video()`, which is an aggregation function that takes a frame index (actually: any expression that can be used to order the frames; a timestamp would also work) and an image, and then assembles the sequence of images into a video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce224393",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[pt.make_video(t.frame_idx, draw_boxes(t.frame, t.detections.boxes))].group_by(t.video).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77731554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
